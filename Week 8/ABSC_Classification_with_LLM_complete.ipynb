{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EB9H7BS_UH1E"
   },
   "source": [
    "# Aspect-Based Sentiment Classification Walkthrough\n",
    "\n",
    "In this notebook, we will explore the process of using LangChain with a large language model (LLM) for aspect-based sentiment classification (ABSC). ABSC is a granular approach to sentiment analysis that determines the sentiment (positive, negative, or neutral) toward specific aspects or attributes within a piece of text.\n",
    "\n",
    "For example, in the sentence:\n",
    "> \"The food at the restaurant was delicious, but the service was slow.\"\n",
    "\n",
    "The sentiment toward the aspect *\"food\"* is positive, while the sentiment toward the aspect *\"service\"* is negative.\n",
    "\n",
    "### Outline\n",
    "\n",
    "In this walkthrough, we will:\n",
    "\n",
    "1. **Load an ABSC Dataset:** Read in a dataset specifically designed for aspect-based sentiment classification. We will use the SemEval 2014 Dataset, which can be downloaded in  handy csv file from [Kaggle](https://www.kaggle.com/datasets/charitarth/semeval-2014-task-4-aspectbasedsentimentanalysis?select=Laptop_Train_v2.csv)\n",
    "2. **Build an LLM Using LangChain and HuggingFace:** Configure the large language model to handle sentiment classification tasks.\n",
    "3. **Craft a Labeling Prompt:** Create a well-structured prompt to guide the LLM in identifying sentiment for specific aspects of text.\n",
    "4. **Classify Dataset Examples:** Use the LLM and the prompt to classify examples in the dataset.\n",
    "5. **Evaluate Performance:** Measure classification accuracy using evaluation metrics such as precision, recall, and F1 score.\n",
    "\n",
    "### Example\n",
    "\n",
    "To understand ABSC better, let’s consider this example:\n",
    "\n",
    "```python\n",
    "review = \"The laptop's performance is outstanding, but the battery life is disappointing.\"\n",
    "aspects = [\"performance\", \"battery life\"]\n",
    "```\n",
    "\n",
    "The expected output is:\n",
    "\n",
    "| Aspect         | Sentiment   |\n",
    "|----------------|-------------|\n",
    "| Performance    | Positive    |\n",
    "| Battery Life   | Negative    |\n",
    "\n",
    "By the end of this notebook, you'll learn how to apply ABSC with LLMs to solve similar problems effectively.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PCM6JGuoUH1I"
   },
   "source": [
    "# Configure the Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 102171,
     "status": "ok",
     "timestamp": 1739975846893,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "6WOciQ0TUH1J",
    "outputId": "c61483ec-634b-426b-96e5-69d845815265"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.3.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.27)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.72 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (0.3.76)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (0.3.11)\n",
      "Requirement already satisfied: langsmith>=0.1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (0.4.27)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.11.9)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.0.43)\n",
      "Requirement already satisfied: requests<3,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (2.32.5)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.72->langchain) (24.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.72->langchain) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2->langchain) (2025.8.3)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.1.17->langchain) (0.24.0)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (0.16.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.17->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: transformers in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (4.56.1)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (3.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.34.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.3.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (24.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2025.9.1)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (2.32.5)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.22.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (1.1.10)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->transformers) (2025.8.3)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-huggingface in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-huggingface) (0.3.76)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-huggingface) (0.22.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-huggingface) (0.34.4)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.27)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (24.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.3.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.10)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.24.0)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: torch in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.8.0)\n",
      "Requirement already satisfied: torchvision in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.23.0)\n",
      "Requirement already satisfied: torchaudio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (2.8.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.19.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (80.9.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.5)\n",
      "Requirement already satisfied: jinja2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torch) (2025.3.0)\n",
      "Requirement already satisfied: numpy in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision) (2.3.2)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: langchain-huggingface in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.70 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-huggingface) (0.3.76)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-huggingface) (0.22.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.33.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-huggingface) (0.34.4)\n",
      "Requirement already satisfied: langsmith>=0.3.45 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.27)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.15.0)\n",
      "Requirement already satisfied: packaging>=23.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (24.0)\n",
      "Requirement already satisfied: pydantic>=2.7.4 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.11.9)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.0.0)\n",
      "Requirement already satisfied: filelock in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (3.19.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2025.3.0)\n",
      "Requirement already satisfied: requests in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (2.32.5)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (4.67.1)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from huggingface-hub>=0.33.4->langchain-huggingface) (1.1.10)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson>=3.9.14 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.11.3)\n",
      "Requirement already satisfied: requests-toolbelt>=1.0.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard>=0.23.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.24.0)\n",
      "Requirement already satisfied: anyio in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (4.9.0)\n",
      "Requirement already satisfied: certifi in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.0.9)\n",
      "Requirement already satisfied: idna in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (3.7)\n",
      "Requirement already satisfied: h11>=0.16 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.16.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from pydantic>=2.7.4->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (0.4.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests->huggingface-hub>=0.33.4->langchain-huggingface) (2.2.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.3.45->langchain-core<1.0.0,>=0.3.70->langchain-huggingface) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.20.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (4.5 kB)\n",
      "Collecting absl-py>=1.0.0 (from tensorflow)\n",
      "  Downloading absl_py-2.3.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=24.3.25 (from tensorflow)\n",
      "  Downloading flatbuffers-25.2.10-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google_pasta>=0.1.1 (from tensorflow)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting libclang>=13.0.0 (from tensorflow)\n",
      "  Downloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl.metadata (5.2 kB)\n",
      "Collecting opt_einsum>=2.3.2 (from tensorflow)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (24.0)\n",
      "Collecting protobuf>=5.28.0 (from tensorflow)\n",
      "  Downloading protobuf-6.32.1-cp39-abi3-macosx_10_9_universal2.whl.metadata (593 bytes)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.32.5)\n",
      "Requirement already satisfied: setuptools in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing_extensions>=3.6.6 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (4.15.0)\n",
      "Collecting wrapt>=1.11.0 (from tensorflow)\n",
      "  Using cached wrapt-1.17.3-cp312-cp312-macosx_11_0_arm64.whl.metadata (6.4 kB)\n",
      "Collecting grpcio<2.0,>=1.24.3 (from tensorflow)\n",
      "  Downloading grpcio-1.75.0-cp312-cp312-macosx_11_0_universal2.whl.metadata (3.7 kB)\n",
      "Collecting tensorboard~=2.20.0 (from tensorflow)\n",
      "  Downloading tensorboard-2.20.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting keras>=3.10.0 (from tensorflow)\n",
      "  Downloading keras-3.11.3-py3-none-any.whl.metadata (5.9 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorflow) (2.3.2)\n",
      "Collecting h5py>=3.11.0 (from tensorflow)\n",
      "  Downloading h5py-3.14.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (2.7 kB)\n",
      "Collecting ml_dtypes<1.0.0,>=0.5.1 (from tensorflow)\n",
      "  Downloading ml_dtypes-0.5.3-cp312-cp312-macosx_10_13_universal2.whl.metadata (8.9 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2025.8.3)\n",
      "Collecting markdown>=2.6.8 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: pillow in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from tensorboard~=2.20.0->tensorflow) (10.3.0)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard~=2.20.0->tensorflow)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Collecting wheel<1.0,>=0.23.0 (from astunparse>=1.6.0->tensorflow)\n",
      "  Downloading wheel-0.45.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting rich (from keras>=3.10.0->tensorflow)\n",
      "  Downloading rich-14.1.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting namex (from keras>=3.10.0->tensorflow)\n",
      "  Downloading namex-0.1.0-py3-none-any.whl.metadata (322 bytes)\n",
      "Collecting optree (from keras>=3.10.0->tensorflow)\n",
      "  Downloading optree-0.17.0-cp312-cp312-macosx_11_0_arm64.whl.metadata (33 kB)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard~=2.20.0->tensorflow) (3.0.2)\n",
      "Collecting markdown-it-py>=2.2.0 (from rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading markdown_it_py-4.0.0-py3-none-any.whl.metadata (7.3 kB)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages (from rich->keras>=3.10.0->tensorflow) (2.19.2)\n",
      "Collecting mdurl~=0.1 (from markdown-it-py>=2.2.0->rich->keras>=3.10.0->tensorflow)\n",
      "  Downloading mdurl-0.1.2-py3-none-any.whl.metadata (1.6 kB)\n",
      "Downloading tensorflow-2.20.0-cp312-cp312-macosx_12_0_arm64.whl (200.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m200.5/200.5 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.75.0-cp312-cp312-macosx_11_0_universal2.whl (11.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.5.3-cp312-cp312-macosx_10_13_universal2.whl (663 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m663.9/663.9 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard-2.20.0-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-any.whl (2.4 kB)\n",
      "Downloading absl_py-2.3.1-py3-none-any.whl (135 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading wheel-0.45.1-py3-none-any.whl (72 kB)\n",
      "Downloading flatbuffers-25.2.10-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp312-cp312-macosx_11_0_arm64.whl (2.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/2.8 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-3.11.3-py3-none-any.whl (1.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-1-py2.py3-none-macosx_11_0_arm64.whl (25.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.8/25.8 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading protobuf-6.32.1-cp39-abi3-macosx_10_9_universal2.whl (426 kB)\n",
      "Downloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Using cached wrapt-1.17.3-cp312-cp312-macosx_11_0_arm64.whl (39 kB)\n",
      "Downloading namex-0.1.0-py3-none-any.whl (5.9 kB)\n",
      "Downloading optree-0.17.0-cp312-cp312-macosx_11_0_arm64.whl (351 kB)\n",
      "Downloading rich-14.1.0-py3-none-any.whl (243 kB)\n",
      "Downloading markdown_it_py-4.0.0-py3-none-any.whl (87 kB)\n",
      "Downloading mdurl-0.1.2-py3-none-any.whl (10.0 kB)\n",
      "Installing collected packages: namex, libclang, flatbuffers, wrapt, wheel, werkzeug, termcolor, tensorboard-data-server, protobuf, optree, opt_einsum, ml_dtypes, mdurl, markdown, h5py, grpcio, google_pasta, gast, absl-py, tensorboard, markdown-it-py, astunparse, rich, keras, tensorflow\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25/25\u001b[0m [tensorflow]5\u001b[0m [tensorflow]]\n",
      "\u001b[1A\u001b[2KSuccessfully installed absl-py-2.3.1 astunparse-1.6.3 flatbuffers-25.2.10 gast-0.6.0 google_pasta-0.2.0 grpcio-1.75.0 h5py-3.14.0 keras-3.11.3 libclang-18.1.1 markdown-3.9 markdown-it-py-4.0.0 mdurl-0.1.2 ml_dtypes-0.5.3 namex-0.1.0 opt_einsum-3.4.0 optree-0.17.0 protobuf-6.32.1 rich-14.1.0 tensorboard-2.20.0 tensorboard-data-server-0.7.2 tensorflow-2.20.0 termcolor-3.1.0 werkzeug-3.1.3 wheel-0.45.1 wrapt-1.17.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m25.1.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pandas\n",
    "! pip install langchain\n",
    "! pip install transformers\n",
    "! pip install langchain-huggingface\n",
    "! pip install torch torchvision torchaudio\n",
    "! pip install --upgrade langchain-huggingface\n",
    "! pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LXakdEC1UH1K"
   },
   "source": [
    "# Read in dataset and investigate the data\n",
    "\n",
    "Make sure to download the data from [Kaggle](https://www.kaggle.com/datasets/charitarth/semeval-2014-task-4-aspectbasedsentimentanalysis?select=Laptop_Train_v2.csv). We'll be working with the ```Laptop_Train_v2.csv```\n",
    "\n",
    "__Prompt__: I would like the python code to read in python dataframe from a csv named \"Laptop_Train_v2.csv\". I would like for you to downsample to 100 entries from the dataframe. Note that for the sampling, use the column 'id' to determine samples. So, there should be 100 unique values of 'id', but there will be more than 100 rows. I would like to also have the code to view the column names, a sample of the entries and summary of the values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 723,
     "status": "ok",
     "timestamp": 1739975847615,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "ggfNSE7wUH1K",
    "outputId": "d131e281-7187-449e-d5a9-8b0efc064401"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file successfully loaded!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name = \"Laptop_Train_v2.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "print(\"CSV file successfully loaded!\")\n",
    "\n",
    "# Downsample to 100 unique 'id' values\n",
    "# smaller sample for testing is selected from the downloaded dataset\n",
    "sampled_ids = df['id'].drop_duplicates().sample(n=100)  # Randomly select 100 unique IDs\n",
    "df = df[df['id'].isin(sampled_ids)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1739975847639,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "qATnM8ZPUH1L",
    "outputId": "5e983eb9-9acd-4aa7-8b6a-ef47bd93acbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Column Names:\n",
      "Index(['id', 'Sentence', 'Aspect Term', 'polarity', 'from', 'to'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Display the column names\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 87,
     "status": "ok",
     "timestamp": 1739975847740,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "9x_4HdKxUH1L",
    "outputId": "9dc04c97-5cc6-486d-dd5c-c3c5bd76bd97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sample Entries:\n",
      "       id                                           Sentence  \\\n",
      "30   1054     -No backlit keyboard, but not an issue for me.   \n",
      "40   1574  I love the operating system and the preloaded ...   \n",
      "41   1574  I love the operating system and the preloaded ...   \n",
      "77    803  It rarely works and when it does it's incredib...   \n",
      "117  1095  I also purchased Office Max's \"Max Assurance\" ...   \n",
      "\n",
      "                      Aspect Term  polarity  from  to  \n",
      "30                       keyboard  conflict    12  20  \n",
      "40               operating system  positive    11  27  \n",
      "41             preloaded software  positive    36  54  \n",
      "77                          works  negative    10  15  \n",
      "117  Office Max's \"Max Assurance\"   neutral    17  45  \n"
     ]
    }
   ],
   "source": [
    "# Display a sample of the entries (first 5 rows by default)\n",
    "print(\"\\nSample Entries:\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1739975847747,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "8V3l1PG8UH1L",
    "outputId": "7407e481-0b86-486a-e2e1-b4db6ece6455"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of Column Values:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 141 entries, 30 to 2328\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           141 non-null    int64 \n",
      " 1   Sentence     141 non-null    object\n",
      " 2   Aspect Term  141 non-null    object\n",
      " 3   polarity     141 non-null    object\n",
      " 4   from         141 non-null    int64 \n",
      " 5   to           141 non-null    int64 \n",
      "dtypes: int64(3), object(3)\n",
      "memory usage: 7.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Display a summary of the values in each column\n",
    "print(\"\\nSummary of Column Values:\")\n",
    "print(df.info())  # Provides information about data types and non-null counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1739975847747,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "upcqdC7OUH1M",
    "outputId": "36a7033f-a4ac-4d51-bb8f-b9a5e02eec20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Statistical Summary:\n",
      "                 id                                           Sentence  \\\n",
      "count    141.000000                                                141   \n",
      "unique          NaN                                                100   \n",
      "top             NaN  Though the picture, video, and music software ...   \n",
      "freq            NaN                                                  4   \n",
      "mean    1613.950355                                                NaN   \n",
      "std      891.907637                                                NaN   \n",
      "min       29.000000                                                NaN   \n",
      "25%      879.000000                                                NaN   \n",
      "50%     1745.000000                                                NaN   \n",
      "75%     2426.000000                                                NaN   \n",
      "max     3072.000000                                                NaN   \n",
      "\n",
      "       Aspect Term  polarity        from          to  \n",
      "count          141       141  141.000000  141.000000  \n",
      "unique         106         4         NaN         NaN  \n",
      "top          price  positive         NaN         NaN  \n",
      "freq             5        65         NaN         NaN  \n",
      "mean           NaN       NaN   40.163121   49.808511  \n",
      "std            NaN       NaN   34.858412   35.358352  \n",
      "min            NaN       NaN    0.000000    5.000000  \n",
      "25%            NaN       NaN   13.000000   21.000000  \n",
      "50%            NaN       NaN   34.000000   43.000000  \n",
      "75%            NaN       NaN   58.000000   70.000000  \n",
      "max            NaN       NaN  220.000000  225.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nStatistical Summary:\")\n",
    "print(df.describe(include='all'))  # Provides a statistical summary for all columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bg9Rozk0UH1M"
   },
   "source": [
    "__prompt__: Okay, now please give me the python code to look at the unique values, along with their counts of the \"polarity\" and the \"Aspect Term\" columns from the dataframe 'df'. You do not need to check for the columns or dataframe; they are already loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1739975847751,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "hfCVx0AmUH1M",
    "outputId": "4994e75f-db1d-49a8-8176-71d07371175a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values and their counts in the 'polarity' column:\n",
      "polarity\n",
      "positive    65\n",
      "negative    54\n",
      "neutral     20\n",
      "conflict     2\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display unique values and their counts for \"polarity\"\n",
    "print(\"\\nUnique values and their counts in the 'polarity' column:\")\n",
    "print(df['polarity'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 104,
     "status": "ok",
     "timestamp": 1739975847856,
     "user": {
      "displayName": "Manu Gupta",
      "userId": "06872556596276847349"
     },
     "user_tz": -330
    },
    "id": "RsizZCalUH1M",
    "outputId": "81961b42-cd45-4e43-838d-414797d400c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Unique values and their counts in the 'Aspect Term' column:\n",
      "Aspect Term\n",
      "price                   5\n",
      "use                     5\n",
      "screen                  5\n",
      "keyboard                4\n",
      "warranty                4\n",
      "                       ..\n",
      "extended warranties     1\n",
      "extended warranty       1\n",
      "loaded                  1\n",
      "GarageBand              1\n",
      "mousepad sensitivity    1\n",
      "Name: count, Length: 106, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display unique values and their counts for \"Aspect Term\"\n",
    "print(\"\\nUnique values and their counts in the 'Aspect Term' column:\")\n",
    "print(df['Aspect Term'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eEpbOaNYUH1M"
   },
   "source": [
    "# Instantiate a LLM for Classification\n",
    "\n",
    "__prompt__: Now, I need you to create an LLM object using LangChain. In particular, I would like to use the text-generation model of \"tiiuae/Falcon3-3B-Instruct\" from HuggingFace and use the 0th GPU. Make sure to import the langchain HuggingFace pipeline as \"from langchain_huggingface import HuggingFacePipeline\". Also, make sure when creating the pipeline to specify \"max_new_tokens = 500\", and make sure the pipeline only outputs the generated text and not the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 338,
     "referenced_widgets": [
      "4cb236b211a84a57a9df9dc2b59ca915",
      "88a9ed5c779c44e39df501f8fab9984e",
      "fe57e5954cb9493f84b4842f810ec7b0",
      "280408967ec646ba9c9d765face6209d",
      "0b3713c2afd74a9fb23dfe153e33d9d0",
      "03a40de991a24cb5810ba52c82965df2",
      "6fabeba2bfe442e794cd32426cd0e70e",
      "c44de7799a4147798e608b587b6b966d",
      "d900cc81bc69430c8fad97c840cd29a8",
      "60ed0dd5a20a435792dcb26f759dd064",
      "9cd05ffce7ba48ed9713b8a7d0c66edf",
      "fa0c6fe5371e4b84b76ff74d8dcc0b3d",
      "066ad96fe8e04757bfaf439aa08b99dd",
      "7f498a16eb764401977885e20d88349d",
      "95b30256ab61473fafb41ae7b754bd1e",
      "5a0f25d243704573a23889f813f73908",
      "bb7356f4f28d4cc3acfef33112dbf604",
      "b88eddfcfc0249e5a02876e9db25dba3",
      "a746ae7230b245018c4433b3d509a896",
      "a2ecb84dc40c4962a9c2b88e25e6f30b",
      "841606ef0aa54d7a9ee8f1e0e6506ac0",
      "d6ecfcebe3df4689b44f4f28ec52b221",
      "fc7176fcc2e7413e84f8d9ce94273ddd",
      "7bfc3981288b451aa339fb6386d62c34",
      "a1ecc6d4cba34a89840a1aacdb8dddd8",
      "c8f4c01561ba4e47a35ef78348ab90b1",
      "45a3a00f6ca946c88b213f14bfab60b2",
      "592e69d898734d74ab1dbcccc7a9a11f",
      "622984569a3548629fd40740244bba2e",
      "6a797df0a0844e8cb6d04358a1ee17ba",
      "8ea03289b0c4482ba118d8b90b191643",
      "5b8d1f66063e468f8b7564a3e43dc9a7",
      "5290097e466f4d0fbfbd1ba8a697ed6d",
      "a5defcb1bad746208822be2d5eaca551",
      "904485f2c6be445b976642dedfa17191",
      "119d9d5686fa402f8c9b302a3d986d28",
      "74bab200d75c4b0d9c6b9225bb1e0d29",
      "d6e524297c794f019adfc97c2f6dcb89",
      "dd0e396baad74b32aee4e05c8de4ad32",
      "7cdcd3800bbb4d72b13eaf0f828b8d2e",
      "ca173a48b18a4126b767252f0a2aecb0",
      "be64c4a5424849ef8b2af663db39a45e",
      "e28434a1de6a48ddaeccaf1590748406",
      "36601d9fb7394e3e893114d195ad4730",
      "fa9c171a2310406eb5256d9fcf3f45a1",
      "e1f0f3ab916e4c099b9e143ab4739ed7",
      "5dfba9dbb0fa4edcb49e21d44614e77e",
      "df6cb4a6a9654a58ab2ca53975f19cb7",
      "797d0b7040d54cf790793ea1f4a3cfbf",
      "03af709f35044e69b3c3b1bf25e1e21c",
      "3a58ba2889fc44d5940cd44d94af26ee",
      "738228c6c1fb45a1a3cb8f43d9ecbcef",
      "01bf8028ff9248efad7933fb51b3baf3",
      "4045ba6f7fda488ab54b378a41a23f5e",
      "ef612e194fc54dd99fc5a465b25146bf",
      "6c7fce0ca53d44b9902cf6a5abfe7581",
      "9f689d078f13482280c1feb7822a1a12",
      "44a38777069d4e9e8d82ee8611d406b0",
      "71952ec84dbe46e38eaa446d98d74f6e",
      "e2cc8ca3212e492b8e890d4c22b41066",
      "c98d1c4cb71a494697cdf9c5565c00a4",
      "617260252b0b4dd09a36a5496ac59dfe",
      "2e5d81217ae74e39917ec20873a91648",
      "c96fa41a542e488da9ee8b9e3bed1476",
      "9c9c152afec34198a3f8dc57ad38e8f3",
      "1fc004033cbe41fb88e89cbb929043fc"
     ]
    },
    "id": "gK78ZmJXUH1M",
    "outputId": "274795f0-ee8a-4818-eb25-651194319025"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'torch' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      6\u001b[39m model_name = \u001b[33m\"\u001b[39m\u001b[33mtiiuae/Falcon3-3B-Instruct\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Create a HuggingFace pipeline with the specified settings\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m text_gen_pipeline = \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext-generation\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Specify the task\u001b[39;49;00m\n\u001b[32m     11\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m   \u001b[49m\u001b[38;5;66;43;03m# Specify the model\u001b[39;49;00m\n\u001b[32m     12\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m           \u001b[49m\u001b[38;5;66;43;03m# Use the 0th GPU\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmax_new_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Limit the number of generated tokens\u001b[39;49;00m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43mreturn_full_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# Ensure the output only includes the generated text \u001b[39;49;00m\n\u001b[32m     15\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Wrap the pipeline with LangChain's HuggingFacePipeline\u001b[39;00m\n\u001b[32m     18\u001b[39m llm = HuggingFacePipeline(pipeline=text_gen_pipeline)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/transformers/pipelines/__init__.py:1018\u001b[39m, in \u001b[36mpipeline\u001b[39m\u001b[34m(task, model, config, tokenizer, feature_extractor, image_processor, processor, framework, revision, use_fast, token, device, device_map, dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[39m\n\u001b[32m   1013\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1014\u001b[39m             \u001b[33m'\u001b[39m\u001b[33mYou cannot use both `pipeline(... dtype=..., model_kwargs=\u001b[39m\u001b[33m{\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m:...})` as those\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m   1015\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m arguments might conflict, use only one.)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1016\u001b[39m         )\n\u001b[32m   1017\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1018\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[43mtorch\u001b[49m, dtype):\n\u001b[32m   1019\u001b[39m         dtype = \u001b[38;5;28mgetattr\u001b[39m(torch, dtype)\n\u001b[32m   1020\u001b[39m     model_kwargs[\u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m] = dtype\n",
      "\u001b[31mNameError\u001b[39m: name 'torch' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the required libraries\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "# Define the model name\n",
    "model_name = \"tiiuae/Falcon3-3B-Instruct\"\n",
    "\n",
    "# Create a HuggingFace pipeline with the specified settings\n",
    "text_gen_pipeline = pipeline(\n",
    "    \"text-generation\",  # Specify the task\n",
    "    model=model_name,   # Specify the model\n",
    "    device=0,           # Use the 0th GPU\n",
    "    max_new_tokens=500, # Limit the number of generated tokens\n",
    "    return_full_text=False # Ensure the output only includes the generated text \n",
    ")\n",
    "\n",
    "# Wrap the pipeline with LangChain's HuggingFacePipeline\n",
    "llm = HuggingFacePipeline(pipeline=text_gen_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cUkUK_dVYfJ7"
   },
   "outputs": [],
   "source": [
    "llm(\"Say Hello\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bGsejLRsUH1N"
   },
   "source": [
    "# Label the Aspects and Sentiments\n",
    "\n",
    "Now, we need to label the aspects and sentiments in the data. We first need to create an aspect sentiment labeling prompt\n",
    "\n",
    "__prompt__: I would like a prompt, formatted as a langchain prompt object, that does aspect-based sentiment classification of a laptop review. The prompt takes in a review of a laptop called {sentence} and does two things. First, it needs to determine what aspects are mentioned in the review. Examples include: 'screen', 'battery life', 'packaging', 'graphics', 'warranty', 'price', 'features'. Each review should have between 1 and 4 aspects, and aspects are usually only one or two word phrases from the review text that describe the laptop. Aspects are usually nouns, and not adverbs or adjectives like \"died\" or \"perfect\".\n",
    "\n",
    "Then for each aspect that is in the review - and only those aspects - it needs to provide the sentiment of the review towards that aspect. The possible sentiment values are \"positive\", \"negative\", \"neutral\", and \"conflict\". The prompt should also specify that the output should be of the form of a list of tuples, where the first entry in the tuple is the aspect, and second entry is the sentiment of the review towards that aspect. The prompt should also specify that the LLM should only output this list of tuples and no other words. So, as an example:\n",
    "\n",
    "sentence: \"The Macbook arrived in a nice twin packing and sealed in the box, all the functions works great.\"\n",
    "output: [('functions', 'positive'),('packaging', 'positive')]\n",
    "\n",
    "sentence: \"The USB port never worked\"\n",
    "output: [('USB port', 'negative')]\n",
    "\n",
    "sentence: \"The price and features more than met my needs.\"\n",
    "output: [('price', 'positive'), ('features', 'positive')]\n",
    "\n",
    "sentence: \"My warranty ran out right as the screen died.\"\n",
    "output: [('warranty', 'negative'), ('screen', 'negative')]\n",
    "\n",
    "sentence: \"The battery has standard life and the shipping was fast.\"\n",
    "output: [('battery', 'neutral'), ('shipping', 'positive')]\n",
    "\n",
    "sentence: \"Just a black screen!\"\n",
    "output: [('screen', 'negative')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bniFGVJkUH1N"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# Define the template for aspect-based sentiment classification\n",
    "template = \"\"\"\n",
    "You are an AI that analyzes laptop reviews and determines the sentiment towards various aspects mentioned in the review.\n",
    "\n",
    "Given a review sentence, do the following:\n",
    "1. Identify the aspects mentioned in the review. Aspects are typically nouns, usually one or two words, and represent features of the laptop (such as 'screen', 'battery life', 'packaging', 'graphics', 'warranty', 'price', 'features'). There should be between 1 and 4 aspects mentioned in the review.\n",
    "2. For each identified aspect, determine the sentiment expressed in the review towards that aspect. The possible sentiments are 'positive', 'negative', 'neutral', or 'conflict'.\n",
    "3. Provide the output as a list of tuples, where the first entry in the tuple is the aspect, and the second entry is the sentiment towards that aspect.\n",
    "\n",
    "The output should only be the list of tuples with the aspects and sentiments and nothing else. Below are some examples:\n",
    "\n",
    "Example 1:\n",
    "Input: \"The Macbook arrived in a nice twin packing and sealed in the box, all the functions works great.\"\n",
    "Output: [('functions', 'positive'), ('packaging', 'positive')]\n",
    "\n",
    "Example 2:\n",
    "Input: \"The USB port never worked.\"\n",
    "Output: [('USB port', 'negative')]\n",
    "\n",
    "Example 3:\n",
    "Input: \"The price and features more than met my needs.\"\n",
    "Output: [('price', 'positive'), ('features', 'positive')]\n",
    "\n",
    "Example 4:\n",
    "Input: \"My warranty ran out right as the screen died.\"\n",
    "Output: [('warranty', 'negative'), ('screen', 'negative')]\n",
    "\n",
    "Example 5:\n",
    "Input: \"The battery has standard life and the shipping was fast.\"\n",
    "Output: [('battery', 'neutral'), ('shipping', 'positive')]\n",
    "\n",
    "Example 6:\n",
    "Input: \"Just a black screen!\"\n",
    "Output: [('screen', 'negative')]\n",
    "\n",
    "Input: \"{sentence}\"\n",
    "Output:\n",
    "\"\"\"\n",
    "\n",
    "# Create the LangChain prompt object\n",
    "prompt = PromptTemplate(input_variables=[\"sentence\"], template=template)\n",
    "\n",
    "# Example usage\n",
    "sentence = \"The battery life was long, but the screen quality was disappointing.\"\n",
    "formatted_prompt = prompt.format(sentence=sentence)\n",
    "print(formatted_prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3oNgaVhNUH1N"
   },
   "outputs": [],
   "source": [
    "example = df.iloc[10,:]\n",
    "\n",
    "print(example['Sentence'])\n",
    "\n",
    "llm(prompt.format(sentence=example['Sentence']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iIoPXuIyUH1N"
   },
   "source": [
    "Now that we have our labeling prompt, lets construct our labeling chain.\n",
    "\n",
    "__prompt__: Now, given the LangChain prompt template \"prompt\", please give me the code to create a langchain chain using the pipe operator \"|\" with the prompt and an LLM called \"llm\". Please also create function to parse the output and remove extraneous output from the llm. Below are some examples:\n",
    "\n",
    "'\\n<|assistant|>\\n[output] \"[\\'hardware\\', \\'positive\\'], [\\'shipping\\', \\'negative\\']\"' -> [('hardware', 'positive'), ('shipping', 'negative')]\n",
    "\"<|assistant|>\\n['camera', 'neutral']\" -> [('camera', 'neutral')]\n",
    "\"<|assistant|>\\n[['graphics', 'positive']], \" -> [('graphics', 'positive')]\n",
    "\"<|assistant|>\\n[('touchpad', 'positive')]\" -> [('touchpad', 'positive')]\n",
    "\"<|assistant|>\\nsomething nonsensical, \" -> [('','')]\n",
    "\n",
    "The chain should resemble: label_prompt | llm | parse_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aDxDFX64UH1N"
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Function to parse the LLM output and remove extraneous content\n",
    "def parse_output(output: str):\n",
    "    try:\n",
    "        # Extract the list of tuples from the LLM output, which could be wrapped in extra characters\n",
    "        parsed_output = ast.literal_eval(output.strip().replace('<|assistant|>', '').strip())\n",
    "\n",
    "        # Ensure the output is a list of tuples\n",
    "        if isinstance(parsed_output, list) and all(isinstance(item, tuple) and len(item) == 2 for item in parsed_output):\n",
    "            return parsed_output\n",
    "        else:\n",
    "            return [('','')]  # Return an empty tuple if the output isn't valid\n",
    "    except Exception as e:\n",
    "        # Handle errors and return empty tuple in case of invalid format\n",
    "        print(f\"Error parsing output: {e}\")\n",
    "        return [('','')]\n",
    "\n",
    "# Define the LLM chain that uses the prompt and LLM\n",
    "chain = prompt | llm | parse_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DCPMyRtfUH1N"
   },
   "outputs": [],
   "source": [
    "print(example['Sentence'])\n",
    "\n",
    "chain.invoke(example['Sentence'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5DUUxdiNUH1N"
   },
   "source": [
    "__prompt__: Now, produce code to iterate through the dataframe \"df\" and do the aspect-based sentiment classifications of the \"Sentence\" column of the dataframe. Please note that you only need to do a labeling for each unique entry in 'id' column. Store the output as a new dataframe called \"results_df\" with columns 'id' and \"aspect_sentiment\". Please also include tqdm to monitor performance into the labeling loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ytA4HViwUH1N"
   },
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "results = []\n",
    "\n",
    "# Iterate through each unique 'id' in the DataFrame using tqdm to monitor progress\n",
    "for unique_id in tqdm(df['id'].drop_duplicates(), desc=\"Processing reviews\", unit=\"id\"):\n",
    "    # Get the first sentence for each unique 'id'\n",
    "    sentence = df[df['id'] == unique_id].iloc[0]['Sentence']\n",
    "\n",
    "    # Get the aspect-based sentiment output\n",
    "    aspect_sentiment = chain.invoke(sentence)\n",
    "\n",
    "    # Append the result to the results list\n",
    "    results.append({'id': unique_id, 'aspect_sentiment': aspect_sentiment})\n",
    "\n",
    "# Create the results DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Show the first few rows of the results DataFrame\n",
    "print(results_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PHFLEVk1UH1O"
   },
   "source": [
    "# Evaluate the Results\n",
    "\n",
    "Now, we need to evaluate the results. One of the difficulties, however, is in the phrasing of the aspects. Its possible to have more than one term describe the same aspect, such as \"battery\" and \"battery life\" in \"the battery life is really good\". In both cases, we are talking about the \"battery\" but an exact match of the aspect words would fail. So, we will use the LLM to assist us in the evaluation of results by comparing entities and mathcing semantically close ones.\n",
    "\n",
    "First, we need to get out all of the aspect based sentiments from the original dataframe\n",
    "\n",
    "__prompt__ I would like the python code to get all of the aspects and their corresponding polarities from the dataframe 'df'. To do this, for each unique id in the column 'id' take out all of the entries from the 'Aspect Term' and 'polarity' columns and combine those into a tuple. Then combine all of the tuples for each unique id into a list. Then create a dataframe with columns 'id' and 'true_aspect_sentiment' from these values. So, for example, if the id '1111' has two entries, than there should be an entry in the new dataframe of {'id':1111, 'true_aspect_sentiment':[('aspect_1', 'sentiment_1'), ('aspect_2', 'sentiment_2')]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kzPoY6kDUH1O"
   },
   "outputs": [],
   "source": [
    "true_aspect_sentiment = []\n",
    "\n",
    "# Iterate through each unique 'id' in the DataFrame\n",
    "for unique_id in df['id'].drop_duplicates():\n",
    "    # Get the rows for the current unique 'id'\n",
    "    subset = df[df['id'] == unique_id]\n",
    "\n",
    "    # Create a list of tuples from the 'Aspect Term' and 'polarity' columns\n",
    "    aspect_sentiment_tuples = list(zip(subset['Aspect Term'], subset['polarity']))\n",
    "\n",
    "    # Append the result to the list, ensuring each entry has 'id' and 'true_aspect_sentiment'\n",
    "    true_aspect_sentiment.append({'id': unique_id, 'true_aspect_sentiment': aspect_sentiment_tuples})\n",
    "\n",
    "# Create the results DataFrame\n",
    "true_aspect_sentiment_df = pd.DataFrame(true_aspect_sentiment)\n",
    "\n",
    "# Show the first few rows of the results DataFrame\n",
    "print(true_aspect_sentiment_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wlj138XhUH1O"
   },
   "source": [
    "__prompt__ now, please give me the code to join 'true_aspect_sentiment_df' with 'results_df' on the 'id' column. Call this dataframe 'eval_df'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "40Gn0WNvUH1O"
   },
   "outputs": [],
   "source": [
    "# Join 'true_aspect_sentiment_df' with 'results_df' on the 'id' column\n",
    "eval_df = pd.merge(true_aspect_sentiment_df, results_df, on='id', how='inner')\n",
    "\n",
    "# Show the first few rows of the resulting 'eval_df'\n",
    "print(eval_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kv07huiZUH1O"
   },
   "source": [
    "Now, let's do the matching of the results, so that we can evaluate how we our LLM and prompt are doing.\n",
    "\n",
    "__prompt__ Please produce prompt to match tuples between two different lists in a langchain prompt template. The LLM will be given two lists of tuples, one called \"true aspect sentiments\" and one called \"predicted aspect sentiments\". The task is to determine for each tuple in the \"true aspect sentiments\" if there is a tuple in \"predicted aspect sentiments\" that closely matches. To do the matching, there are two steps. First, you need to determine if the first entry in the tuples are describing the same things. For example, \"battery\" and \"battery life\" are roughly describing the same things, while \"operating system\" and \"packaging\" are not. In other words, you must determine if the two first entries are semantically very close. Then, if the first entries of the tuples match, compare the second entries of the tuples for matching. The second entries are the sentiment terms and should match exactly. For example \"positive\" and \"positive\" match, but \"neutral\" and \"negative\" do not. Once you have match for a tuple, move to the next tuple; for each tuple in \"true aspect sentiments\", only count if it has at least one match. Finally, output the number of matches you have as a number (i.e., 0,1,2, etc.). Below are some examples to help you format this prompt for the LLM:\n",
    "\n",
    "Example 1:\n",
    "true aspect sentiments: [(suite of software, positive)]\n",
    "predicted aspect sentiments: [(software, positive), (suite, positive)]\n",
    "output: 1\n",
    "\n",
    "Example 2\n",
    "true aspect sentiments: [('space', 'positive'), ('keyboard', 'negative')]\n",
    "predicted aspect sentiments: [('extra space', 'positive'), ('keyboard', 'negative')]\n",
    "output: 2\n",
    "\n",
    "Example 3\n",
    "true aspect sentiments: [('price premium', 'negative'), ('features', 'positive')]\n",
    "predicted aspect sentiments: [('price', 'neutral'), ('features', 'positive')]\n",
    "output: 1\n",
    "\n",
    "Example 4\n",
    "true aspect sentiments: [('web cam', 'neutral'), (\"burn cd's\", 'neutral')]\n",
    "predicted aspect sentiments: [('web cam', 'negative'), ('cd burning', 'negative')]\n",
    "output: 0\n",
    "\n",
    "Example 5\n",
    "true aspect sentiments: [('space', 'positive'), ('keyboard', 'negative')]\n",
    "predicted aspect sentiments: [('storage', 'positive'), ('screen', 'negative')]\n",
    "output: 1\n",
    "\n",
    "Example 6\n",
    "true aspect sentiments: [('battery life', 'positive')]\n",
    "predicted aspect sentiments: [('battery life', 'positive'), ('battery', 'positive')]\n",
    "output: 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AbHIccjJUH1O"
   },
   "outputs": [],
   "source": [
    "eval_prompt = PromptTemplate(\n",
    "    input_variables=[\"true_aspect_sentiments\", \"predicted_aspect_sentiments\"],\n",
    "    template=\"\"\"\n",
    "You are given two lists of tuples. Each tuple consists of an aspect and a sentiment.\n",
    "Your task is to determine how many tuples in the predicted aspect sentiments list closely match tuples in the true aspect sentiments list.\n",
    "\n",
    "To match:\n",
    "1. First, you need to determine if the first entry (the aspect) in the tuples is describing the same thing. For example, \"battery\" and \"battery life\" are roughly describing the same thing, but \"operating system\" and \"packaging\" are not.\n",
    "2. If the first entries match, then check if the second entries (the sentiment values) are the same. For example, \"positive\" matches \"positive\", but \"positive\" does not match \"neutral\".\n",
    "3. Count each tuple in the true aspect sentiments list only if it has at least one match in the predicted aspect sentiments list.\n",
    "\n",
    "Please output the number of exact matches you find between the two lists. If no matches are found, output 0. Below are some examples:\n",
    "\n",
    "Example 1:\n",
    "true aspect sentiments: [(suite of software, positive)]\n",
    "predicted aspect sentiments: [(software, positive), (suite, positive)]\n",
    "output: 1\n",
    "\n",
    "Example 2:\n",
    "true aspect sentiments: [('space', 'positive'), ('keyboard', 'negative')]\n",
    "predicted aspect sentiments: [('extra space', 'positive'), ('keyboard', 'negative')]\n",
    "output: 2\n",
    "\n",
    "Example 3:\n",
    "true aspect sentiments: [('price premium', 'negative'), ('features', 'positive')]\n",
    "predicted aspect sentiments: [('price', 'neutral'), ('features', 'positive')]\n",
    "output: 1\n",
    "\n",
    "Example 4:\n",
    "true aspect sentiments: [('web cam', 'neutral'), (\"burn cd's\", 'neutral')]\n",
    "predicted aspect sentiments: [('web cam', 'negative'), ('cd burning', 'negative')]\n",
    "output: 0\n",
    "\n",
    "Example 5:\n",
    "true aspect sentiments: [('space', 'positive'), ('keyboard', 'negative')]\n",
    "predicted aspect sentiments: [('storage', 'positive'), ('screen', 'negative')]\n",
    "output: 1\n",
    "\n",
    "Example 6:\n",
    "true aspect sentiments: [('battery life', 'positive')]\n",
    "predicted aspect sentiments: [('battery life', 'positive'), ('battery', 'positive')]\n",
    "output: 1\n",
    "\n",
    "Here are the two lists:\n",
    "\n",
    "true aspect sentiments: {true_aspect_sentiments}\n",
    "predicted aspect sentiments: {predicted_aspect_sentiments}\n",
    "\n",
    "Your output should be the number of matching tuples. Do not provide any additional words or explanations.\n",
    "\n",
    "output:\"\"\"\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q8mJwegpUH1O"
   },
   "source": [
    "__prompt__ now, please include the prompt object (which should be named \"eval_prompt\") into a langchain chain with the llm object \"llm\" using the \"|\" operator. Please aslo add a final function to the chain that parses the output into an integer format. So, the chain should look like\n",
    "\n",
    "eval_chain = eval_prompt | llm | number_parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64ZBhFV9UH1O"
   },
   "outputs": [],
   "source": [
    "def number_parser(output: str) -> int:\n",
    "    try:\n",
    "        # Parse the number from the output, ensuring it's an integer\n",
    "        return int(output.strip())\n",
    "    except ValueError:\n",
    "        # In case the output is invalid, return 0 (or handle as needed)\n",
    "        return 0\n",
    "\n",
    "# Build the eval_chain with eval_prompt, llm, and number_parser\n",
    "eval_chain = eval_prompt | llm | number_parser\n",
    "\n",
    "# Example usage\n",
    "output = eval_chain.invoke({\n",
    "    \"true_aspect_sentiments\": [('price premium', 'negative'), ('features', 'positive')],\n",
    "    \"predicted_aspect_sentiments\": [('price', 'neutral'), ('features', 'positive')]\n",
    "})\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v_Vz79R5UH1O"
   },
   "source": [
    "__prompt__ Now, please give me the code to use the eval_chain on each entry in the eval_df. For the \"true_aspect_sentiments\" take the values from the \"true_aspect_sentiment\" column and for the \"predicted_aspect_sentiments\" take the values from the aspect_sentiment. Please save the outputs in a new column called \"matches\". Please also use tqdm when iterating over the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8sYiPHBDUH1O"
   },
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "\n",
    "# Create a function to apply eval_chain on each row of the dataframe\n",
    "def apply_eval_chain(row):\n",
    "    true_aspect_sentiments = row['true_aspect_sentiment']\n",
    "    predicted_aspect_sentiments = row['aspect_sentiment']\n",
    "\n",
    "    # Use the eval_chain to get the number of matches\n",
    "    return eval_chain.invoke({\n",
    "        \"true_aspect_sentiments\": true_aspect_sentiments,\n",
    "        \"predicted_aspect_sentiments\": predicted_aspect_sentiments\n",
    "    })\n",
    "\n",
    "eval_df['matches'] = eval_df.progress_apply(apply_eval_chain, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ORD1_-lkUH1O"
   },
   "outputs": [],
   "source": [
    "eval_df['matches'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FBFKors7UH1P"
   },
   "source": [
    "__prompt__ Now, please give me the code to get the number of tuples in each list in the 'true_aspect_sentiment' column of \"eval_df\" and save that to the column \"num_true_aspects\". Also do the same for the 'aspect_sentiment' and call the column \"num_pred_aspects\". Finally, using the counts in the 'matches' column and the \"num_true_aspects\" compute the difference between them and divide this result by the value in \"num_true_aspects\", then subtract this vaue from 1.0, and take the min of this value an 1.0 (i.e., there should never be a result larger than 1.0). Then, save this result in a new column called \"accuracy\"\n",
    "\n",
    "Finally, give the code for computing the statistics from the \"accuracy\" column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4J7m-B-tUH1P"
   },
   "outputs": [],
   "source": [
    "# Compute the number of tuples in each list in 'true_aspect_sentiment' and 'aspect_sentiment' columns\n",
    "eval_df['num_true_aspects'] = eval_df['true_aspect_sentiment'].apply(len)\n",
    "eval_df['num_pred_aspects'] = eval_df['aspect_sentiment'].apply(len)\n",
    "\n",
    "# Compute the accuracy based on the formula\n",
    "eval_df['accuracy'] = (\n",
    "    1.0 - ((eval_df['num_true_aspects'] - eval_df['matches']) / eval_df['num_true_aspects'])\n",
    ").clip(upper=1.0)  # Ensure accuracy does not exceed 1.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xgjjlsLsUH1P"
   },
   "outputs": [],
   "source": [
    "# Compute basic statistics for the 'accuracy' column\n",
    "accuracy_stats = eval_df['accuracy'].describe()\n",
    "\n",
    "# Optionally, compute additional statistics like mean, median, etc.\n",
    "accuracy_mean = eval_df['accuracy'].mean()\n",
    "accuracy_median = eval_df['accuracy'].median()\n",
    "accuracy_std = eval_df['accuracy'].std()\n",
    "\n",
    "# Print the statistics\n",
    "print(\"Accuracy Statistics:\")\n",
    "print(accuracy_stats)\n",
    "print(f\"Mean Accuracy: {accuracy_mean:.4f}\")\n",
    "print(f\"Median Accuracy: {accuracy_median:.4f}\")\n",
    "print(f\"Standard Deviation of Accuracy: {accuracy_std:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1wtH9KQLUH1P"
   },
   "source": [
    "__prompt__ finally, please give the python code to plot a histogram of the \"accuracy\" column of \"eval_df\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8BZQ50RrUH1P"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot a histogram of the 'accuracy' column\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(eval_df['accuracy'], bins=20, edgecolor='black', alpha=0.7)\n",
    "plt.title('Distribution of Accuracy', fontsize=16)\n",
    "plt.xlabel('Accuracy', fontsize=14)\n",
    "plt.ylabel('Frequency', fontsize=14)\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CwL6GeFtUH1P"
   },
   "source": [
    "__prompt__ What would be a good way to measure performance in this scenario? I have the number of correct matches in \"matches\", the number of aspect sentiments that should have been produced in \"num_true_aspects\" and the number of predicted aspects in \"num_pred_aspects\". Ideally, the number of correct matches should exactly match \"num_true_aspects\", and \"num_true_aspects\" should exactly match \"num_pred_aspects\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BOz7TLNUUH1X"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate Precision, Recall, and F1 score\n",
    "precision = eval_df['matches'].sum() / eval_df['num_pred_aspects'].sum()\n",
    "recall = eval_df['matches'].sum() / eval_df['num_true_aspects'].sum()\n",
    "f1 = 2 * (precision * recall) / (precision + recall)\n",
    "\n",
    "# Calculate Match Efficiency\n",
    "match_efficiency = 1.0 - abs(eval_df['num_pred_aspects'].sum() - eval_df['num_true_aspects'].sum()) / eval_df['num_true_aspects'].sum()\n",
    "\n",
    "# Print the performance metrics\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Match Efficiency: {match_efficiency:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZNfvO4koUH1Y"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "01bf8028ff9248efad7933fb51b3baf3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "03a40de991a24cb5810ba52c82965df2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "03af709f35044e69b3c3b1bf25e1e21c": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "066ad96fe8e04757bfaf439aa08b99dd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bb7356f4f28d4cc3acfef33112dbf604",
      "placeholder": "​",
      "style": "IPY_MODEL_b88eddfcfc0249e5a02876e9db25dba3",
      "value": "model.safetensors.index.json: 100%"
     }
    },
    "0b3713c2afd74a9fb23dfe153e33d9d0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "119d9d5686fa402f8c9b302a3d986d28": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ca173a48b18a4126b767252f0a2aecb0",
      "max": 4989378032,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_be64c4a5424849ef8b2af663db39a45e",
      "value": 4989378032
     }
    },
    "1fc004033cbe41fb88e89cbb929043fc": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "280408967ec646ba9c9d765face6209d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_60ed0dd5a20a435792dcb26f759dd064",
      "placeholder": "​",
      "style": "IPY_MODEL_9cd05ffce7ba48ed9713b8a7d0c66edf",
      "value": " 658/658 [00:00&lt;00:00, 68.5kB/s]"
     }
    },
    "2e5d81217ae74e39917ec20873a91648": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36601d9fb7394e3e893114d195ad4730": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3a58ba2889fc44d5940cd44d94af26ee": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4045ba6f7fda488ab54b378a41a23f5e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "44a38777069d4e9e8d82ee8611d406b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2e5d81217ae74e39917ec20873a91648",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c96fa41a542e488da9ee8b9e3bed1476",
      "value": 1
     }
    },
    "45a3a00f6ca946c88b213f14bfab60b2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "4cb236b211a84a57a9df9dc2b59ca915": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_88a9ed5c779c44e39df501f8fab9984e",
       "IPY_MODEL_fe57e5954cb9493f84b4842f810ec7b0",
       "IPY_MODEL_280408967ec646ba9c9d765face6209d"
      ],
      "layout": "IPY_MODEL_0b3713c2afd74a9fb23dfe153e33d9d0"
     }
    },
    "5290097e466f4d0fbfbd1ba8a697ed6d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "592e69d898734d74ab1dbcccc7a9a11f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5a0f25d243704573a23889f813f73908": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5b8d1f66063e468f8b7564a3e43dc9a7": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5dfba9dbb0fa4edcb49e21d44614e77e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_738228c6c1fb45a1a3cb8f43d9ecbcef",
      "max": 1465955608,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_01bf8028ff9248efad7933fb51b3baf3",
      "value": 1465955608
     }
    },
    "60ed0dd5a20a435792dcb26f759dd064": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "617260252b0b4dd09a36a5496ac59dfe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "622984569a3548629fd40740244bba2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "6a797df0a0844e8cb6d04358a1ee17ba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6c7fce0ca53d44b9902cf6a5abfe7581": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9f689d078f13482280c1feb7822a1a12",
       "IPY_MODEL_44a38777069d4e9e8d82ee8611d406b0",
       "IPY_MODEL_71952ec84dbe46e38eaa446d98d74f6e"
      ],
      "layout": "IPY_MODEL_e2cc8ca3212e492b8e890d4c22b41066"
     }
    },
    "6fabeba2bfe442e794cd32426cd0e70e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "71952ec84dbe46e38eaa446d98d74f6e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_9c9c152afec34198a3f8dc57ad38e8f3",
      "placeholder": "​",
      "style": "IPY_MODEL_1fc004033cbe41fb88e89cbb929043fc",
      "value": " 1/2 [00:22&lt;00:22, 22.17s/it]"
     }
    },
    "738228c6c1fb45a1a3cb8f43d9ecbcef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74bab200d75c4b0d9c6b9225bb1e0d29": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e28434a1de6a48ddaeccaf1590748406",
      "placeholder": "​",
      "style": "IPY_MODEL_36601d9fb7394e3e893114d195ad4730",
      "value": " 4.99G/4.99G [01:58&lt;00:00, 42.2MB/s]"
     }
    },
    "797d0b7040d54cf790793ea1f4a3cfbf": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7bfc3981288b451aa339fb6386d62c34": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_592e69d898734d74ab1dbcccc7a9a11f",
      "placeholder": "​",
      "style": "IPY_MODEL_622984569a3548629fd40740244bba2e",
      "value": "Downloading shards: 100%"
     }
    },
    "7cdcd3800bbb4d72b13eaf0f828b8d2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "7f498a16eb764401977885e20d88349d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a746ae7230b245018c4433b3d509a896",
      "max": 16519,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_a2ecb84dc40c4962a9c2b88e25e6f30b",
      "value": 16519
     }
    },
    "841606ef0aa54d7a9ee8f1e0e6506ac0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "88a9ed5c779c44e39df501f8fab9984e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03a40de991a24cb5810ba52c82965df2",
      "placeholder": "​",
      "style": "IPY_MODEL_6fabeba2bfe442e794cd32426cd0e70e",
      "value": "config.json: 100%"
     }
    },
    "8ea03289b0c4482ba118d8b90b191643": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "904485f2c6be445b976642dedfa17191": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd0e396baad74b32aee4e05c8de4ad32",
      "placeholder": "​",
      "style": "IPY_MODEL_7cdcd3800bbb4d72b13eaf0f828b8d2e",
      "value": "model-00001-of-00002.safetensors: 100%"
     }
    },
    "95b30256ab61473fafb41ae7b754bd1e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_841606ef0aa54d7a9ee8f1e0e6506ac0",
      "placeholder": "​",
      "style": "IPY_MODEL_d6ecfcebe3df4689b44f4f28ec52b221",
      "value": " 16.5k/16.5k [00:00&lt;00:00, 1.68MB/s]"
     }
    },
    "9c9c152afec34198a3f8dc57ad38e8f3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cd05ffce7ba48ed9713b8a7d0c66edf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "9f689d078f13482280c1feb7822a1a12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c98d1c4cb71a494697cdf9c5565c00a4",
      "placeholder": "​",
      "style": "IPY_MODEL_617260252b0b4dd09a36a5496ac59dfe",
      "value": "Loading checkpoint shards:  50%"
     }
    },
    "a1ecc6d4cba34a89840a1aacdb8dddd8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6a797df0a0844e8cb6d04358a1ee17ba",
      "max": 2,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8ea03289b0c4482ba118d8b90b191643",
      "value": 2
     }
    },
    "a2ecb84dc40c4962a9c2b88e25e6f30b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a5defcb1bad746208822be2d5eaca551": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_904485f2c6be445b976642dedfa17191",
       "IPY_MODEL_119d9d5686fa402f8c9b302a3d986d28",
       "IPY_MODEL_74bab200d75c4b0d9c6b9225bb1e0d29"
      ],
      "layout": "IPY_MODEL_d6e524297c794f019adfc97c2f6dcb89"
     }
    },
    "a746ae7230b245018c4433b3d509a896": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b88eddfcfc0249e5a02876e9db25dba3": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bb7356f4f28d4cc3acfef33112dbf604": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "be64c4a5424849ef8b2af663db39a45e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c44de7799a4147798e608b587b6b966d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c8f4c01561ba4e47a35ef78348ab90b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_5b8d1f66063e468f8b7564a3e43dc9a7",
      "placeholder": "​",
      "style": "IPY_MODEL_5290097e466f4d0fbfbd1ba8a697ed6d",
      "value": " 2/2 [02:34&lt;00:00, 69.63s/it]"
     }
    },
    "c96fa41a542e488da9ee8b9e3bed1476": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c98d1c4cb71a494697cdf9c5565c00a4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ca173a48b18a4126b767252f0a2aecb0": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6e524297c794f019adfc97c2f6dcb89": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6ecfcebe3df4689b44f4f28ec52b221": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d900cc81bc69430c8fad97c840cd29a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "dd0e396baad74b32aee4e05c8de4ad32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df6cb4a6a9654a58ab2ca53975f19cb7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4045ba6f7fda488ab54b378a41a23f5e",
      "placeholder": "​",
      "style": "IPY_MODEL_ef612e194fc54dd99fc5a465b25146bf",
      "value": " 1.47G/1.47G [00:34&lt;00:00, 42.3MB/s]"
     }
    },
    "e1f0f3ab916e4c099b9e143ab4739ed7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_03af709f35044e69b3c3b1bf25e1e21c",
      "placeholder": "​",
      "style": "IPY_MODEL_3a58ba2889fc44d5940cd44d94af26ee",
      "value": "model-00002-of-00002.safetensors: 100%"
     }
    },
    "e28434a1de6a48ddaeccaf1590748406": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e2cc8ca3212e492b8e890d4c22b41066": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ef612e194fc54dd99fc5a465b25146bf": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fa0c6fe5371e4b84b76ff74d8dcc0b3d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_066ad96fe8e04757bfaf439aa08b99dd",
       "IPY_MODEL_7f498a16eb764401977885e20d88349d",
       "IPY_MODEL_95b30256ab61473fafb41ae7b754bd1e"
      ],
      "layout": "IPY_MODEL_5a0f25d243704573a23889f813f73908"
     }
    },
    "fa9c171a2310406eb5256d9fcf3f45a1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e1f0f3ab916e4c099b9e143ab4739ed7",
       "IPY_MODEL_5dfba9dbb0fa4edcb49e21d44614e77e",
       "IPY_MODEL_df6cb4a6a9654a58ab2ca53975f19cb7"
      ],
      "layout": "IPY_MODEL_797d0b7040d54cf790793ea1f4a3cfbf"
     }
    },
    "fc7176fcc2e7413e84f8d9ce94273ddd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7bfc3981288b451aa339fb6386d62c34",
       "IPY_MODEL_a1ecc6d4cba34a89840a1aacdb8dddd8",
       "IPY_MODEL_c8f4c01561ba4e47a35ef78348ab90b1"
      ],
      "layout": "IPY_MODEL_45a3a00f6ca946c88b213f14bfab60b2"
     }
    },
    "fe57e5954cb9493f84b4842f810ec7b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c44de7799a4147798e608b587b6b966d",
      "max": 658,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d900cc81bc69430c8fad97c840cd29a8",
      "value": 658
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
