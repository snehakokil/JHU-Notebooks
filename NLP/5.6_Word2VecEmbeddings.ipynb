{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Vector Embeddings using Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the gensim library used for Word2Vec requires a numpy version below 2.0, while we have been using more recent versions which is incompatible.  To resolve this, you may need to downgrade numpy to a compatible version.  If you get an error message when you run the code block to pre-process text, you will likely need to restart the Jupyter kernel.  To do this, open the command palette by pressing Cmd+Shift+P (Mac) or Ctrl+Shift+P (Windows) and look for the dropdown that says \"Jupyter: Restart Kernel\".  This will clear variables and provide a clean slate for this code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downgrade numpy to a compatible version for the gensim library.\n",
    "\n",
    "# First, completely remove NumPy to ensure there are no conflicting versions installed\n",
    "!pip uninstall -y numpy\n",
    "!pip cache purge\n",
    "\n",
    "# Next, reinstall NumPy to a version earlier than 2.0\n",
    "!pip install \"numpy<2.0\"\n",
    "\n",
    "import numpy as np\n",
    "print(\"NumPy version:\", np.__version__)\n",
    "print(\"NumPy location:\", np.__file__)\n",
    "\n",
    "# Make sure that gensim is using the correct NumPy version\n",
    "!pip install --force-reinstall gensim \"numpy<2.0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install necessary libraries if you have not already done so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install pandas\n",
    "!pip install gensim\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import necessary libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a toy dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset\n",
    "data = {\n",
    "    \"tweet\": [\n",
    "        \"I love the new iPhone! It's fantastic. #Apple\",\n",
    "        \"The service at this restaurant was terrible. Never going back. #Disappointed\",\n",
    "        \"Tesla's new model is groundbreaking! #Innovation\",\n",
    "        \"I had an average experience with the product. It's okay. #Neutral\",\n",
    "    ]\n",
    "}\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we preprocess our data.  The first step is to tokenize the tweets.  As you look at the code, think about what it is doing.\n",
    "\n",
    "The next step is to train our Word2Vec model.  Copy this line of code into ChatGPT and ask it to explain the model parameters to you.\n",
    "\n",
    "Finally we will store the word vectors from the \"model\" into a new variable called word_vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing: Tokenize tweets\n",
    "df[\"tokens\"] = df[\"tweet\"].str.lower().str.split()\n",
    "\n",
    "# Train Word2Vec model\n",
    "model = Word2Vec(sentences=df[\"tokens\"], vector_size=50, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get embeddings for words in the vocabulary\n",
    "word_vectors = model.wv\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function is used to visualize the word embeddings using t-SNE.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize embeddings using t-SNE\n",
    "def plot_word_embeddings(word_vectors):\n",
    "    words = list(word_vectors.key_to_index.keys())\n",
    "    vectors = word_vectors[words]\n",
    "    \n",
    "    # Reduce dimensions for visualization\n",
    "    tsne = TSNE(n_components=2, random_state=42)\n",
    "    reduced_vectors = tsne.fit_transform(vectors)\n",
    "    \n",
    "    # Plot the embeddings\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    for i, word in enumerate(words):\n",
    "        plt.scatter(reduced_vectors[i, 0], reduced_vectors[i, 1])\n",
    "        plt.text(reduced_vectors[i, 0] + 0.01, reduced_vectors[i, 1] + 0.01, word, fontsize=9)\n",
    "    plt.title(\"Word2Vec Embeddings Visualization\")\n",
    "    plt.show()\n",
    "\n",
    "plot_word_embeddings(word_vectors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
